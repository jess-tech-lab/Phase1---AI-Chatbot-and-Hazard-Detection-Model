# ğŸ›¡ï¸ Hazard Detection & AI Chatbot  

This project combines **computer vision** and **AI voice assistance** into a single web app.  
Itâ€™s designed to help detect hazards from images or video and let users issue commands using speech.  

---

## ğŸŒŸ What It Does  
- **Hazard Detection (YOLOv8)**  
  - Upload an image or use a webcam/video  
  - Hazards are automatically detected and highlighted  

- **Voice Commands (Whisper)**  
  - Speak commands (e.g., schedule an event, trigger hazard detection)  
  - Speech is transcribed and processed by the chatbot pipeline  

- **Smart Chatbot**  
  - Delegates conversations to the right persona (e.g., based on user profile)  
  - Can connect to external tools like **Google Calendar** to create events  

- **Web Interface (Flask)**  
  - Simple homepage with navigation  
  - Upload images/audio directly from your browser  

---

## ğŸ–¼ï¸ Demo Flow  
1. Go to the homepage  
2. Upload an image â†’ see hazards marked  
3. Upload an audio file â†’ get transcription & action (e.g., â€œAdd doctorâ€™s appointment tomorrowâ€)  
4. (Optional) Run in CLI mode to control via microphone  

---

## ğŸ“‚ Tech Stack  
- **Flask** â€“ web framework  
- **YOLOv8** â€“ hazard detection (computer vision)  
- **Whisper** â€“ speech-to-text  
- **Qdrant + LLMs** â€“ persona-aware chatbot & delegation  
- **Google Calendar API** â€“ event creation  

---

## ğŸš§ Status  
- Core features (hazard detection & voice transcription) are working  
- Chatbot pipeline and Google Calendar integration are functional but still experimental  
- Web templates are minimal (UI is very basic for now)  

---

## ğŸ¤ Contributors  
Core Members and TPMs of the FORTif.ai: Assistant For Independent and Safe Senior Living.  
